from scipy.optimize import minimize
from plotly.offline import iplot, init_notebook_mode
from statsmodels.regression.linear_model import OLS  # çº¿æ€§å›å½’
import plotly as py
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
import plotly.figure_factory as ff
import seaborn as sns
import tushare as ts
pro = ts.pro_api('8e812052c92d7a829f0e3b0197d248e48bb2ba3efbbaa60f505e6852')
import holoviews as hv
import streamlit as st
import pandas as pd
import numpy as np
from plotly.subplots import make_subplots
from datetime import datetime, time, timedelta,date
plt.rcParams['font.sans-serif']=['SimHei']
plt.rcParams['axes.unicode_minus'] =False #å‡å·unicodeç¼–ç 
st.set_page_config(page_icon="ğŸ˜",)
st.markdown("# åŸºé‡‘æ‹©è‚¡æ‹©æ—¶èƒ½åŠ›åˆ†æ")
st.sidebar.header("åŸºé‡‘æ‹©è‚¡æ‹©æ—¶èƒ½åŠ›åˆ†æ")
start_date = st.date_input(
    "è¯·é€‰æ‹©å¼€å§‹æ—¥æœŸ",
    date(2020,2,9))
#st.write('å¼€å§‹æ—¥æœŸ:', start_date)
å¼€å§‹=str(start_date)[:4]+str(start_date)[5:7]+str(start_date)[8:]
end_date = st.date_input(
    "è¯·é€‰æ‹©ç»“æŸæ—¥æœŸ",
    date(2021,5,9))
#st.write('ç»“æŸæ—¥æœŸ:',end_date)
ç»“æŸ=str(end_date)[:4]+str(end_date)[5:7]+str(end_date)[8:]
code=st.text_input('è¯·è¾“å…¥åŸºé‡‘ä»£ç ä¾‹å¦‚000001.OF')
index=st.text_input('è¯·è¾“å…¥æŒ‡æ•°ä»£ç ä¾‹å¦‚000300.SH')
if index:
    df = pro.fund_nav(ts_code=code,start_date=å¼€å§‹,end_date=ç»“æŸ,fields=['ts_code','nav_date','accum_nav'])
    df8=df.sort_values(by='nav_date',ignore_index=True)
    df2=df8.rename(columns={'nav_date':'time'})
    df0=df2[['time','accum_nav']]
    df0['pre_cumulative_nav'] = df0['accum_nav'].shift(1)
    df9=df0.set_index('time')
    df1 = df9[å¼€å§‹:ç»“æŸ]
    #df_one['fundsname'] = df_fund_info.fundsname.values[0]
    dfp=df = pro.index_daily(ts_code='000300.SH', start_date=å¼€å§‹, end_date=ç»“æŸ,fields=['ts_code','trade_date','close'])
    dfg=dfp.rename(columns={'trade_date':'time'})
    dfg1=dfg.sort_values(by='time',ignore_index=True)
    df_index_day=dfg1.set_index('time')
    nav_one = pd.merge(df1, df_index_day, left_index=True,
                            right_index=True, how='left')
    nav_one['cumulative_nav_pct'] = nav_one['accum_nav'].pct_change()
    nav_one['close_pct'] = nav_one['close'].pct_change()
    nav_df_part=nav_one
#if len(nav_df_part['accum_nav'])>2:
    adj_nav_end = list(nav_df_part['accum_nav'])[-1]  # å¤æƒç´¯è®¡å‡€å€¼çš„åŒºé—´æœ«ä½æ•°å€¼
    adj_nav_start = list(nav_df_part['accum_nav'])[0]  # å¤æƒç´¯è®¡å‡€å€¼çš„åŒºé—´é¦–ä½æ•°å€¼
    nav_shift1_start = list(nav_df_part['pre_cumulative_nav'])[0]
# å¤æƒç´¯è®¡å‡€å€¼å½’ä¸€ã€æŒ‡æ•°æ”¶ç›˜ä»·å½’ä¸€,å¾…åç»­ä½¿ç”¨
    nav_df_part['nav_unit'] = nav_df_part['accum_nav'] / adj_nav_start

    nav_df_part['close_unit'] = nav_df_part['close'] / \
        list(nav_df_part['close'])[0]
    # æ ·æœ¬æœŸçš„ç»å¯¹æ”¶ç›Šç‡
    abs_ret = (adj_nav_end/adj_nav_start)-1
        #æ ·æœ¬æœŸçš„å¹´åŒ–æ”¶ç›Šç‡
    annual_ret = pow(adj_nav_end/adj_nav_start, 250/(len(nav_df_part)-1))-1

    #è®¡ç®—èƒœç‡
    fenmu=len(nav_df_part)
    sd=nav_df_part.loc[nav_df_part['cumulative_nav_pct']>0]
    fenzi=len(sd)
    victory_days=fenzi/fenmu
    #æ ·æœ¬æœŸçš„æœ€å¤§å›æ’¤
    #nav_df_part=nav_one
    interval_max_down = ((nav_df_part['accum_nav'].cummax()-nav_df_part['accum_nav']) /
                        (nav_df_part['accum_nav'].cummax())).max()

    # æ ·æœ¬æœŸå¹´åŒ–æ³¢åŠ¨ç‡
    
    annual_var = nav_df_part['cumulative_nav_pct'].std(
            ddof=1)*pow(250, 0.5)

    # æ ·æœ¬æœŸé—´å¹´åŒ–å¤æ™®ï¼Œå¹´åŒ–åçš„å¹³å‡æ”¶ç›Šç‡-æ— é£é™©åˆ©ç‡ /å¹´åŒ–åçš„æ³¢åŠ¨ç‡
    rf_rate=0.02
    annual_sharpe = (
            pow((1+nav_df_part['cumulative_nav_pct'].mean()), 250)-1-rf_rate)/annual_var
    #è®¡ç®—å¡ç›æ¯”ç‡
    interval_calmar = annual_ret/interval_max_down

    # æ ·æœ¬æœŸä¸‹è¡Œæ³¢åŠ¨ç‡
    temp = nav_df_part[nav_df_part['cumulative_nav_pct']
                        < nav_df_part['cumulative_nav_pct'].mean()]
    temp2 = temp['cumulative_nav_pct'] - \
            nav_df_part['cumulative_nav_pct'].mean()
    down_var = np.sqrt((temp2**2).sum()/(len(nav_df_part)-1))*pow(250, 0.5)
    df_a_t = nav_df_part
    rf_rate=0.02
    df_a_t['rf'] = rf_rate/250  # æ—¥åº¦
                # ä»¥ä¸Šæ•°æ®æ•´åˆå®Œæ¯•

                # å®Œå–„æ¨¡å‹è‡ªå˜é‡å’Œå› å˜é‡æ•°æ®
    df_a_t['rprf'] = df_a_t['cumulative_nav_pct'] - df_a_t['rf']  # å› å˜é‡rp-rf
    df_a_t['rmrf'] = df_a_t['close_pct'] - df_a_t['rf']  # è‡ªå˜é‡rm-rf
    df_a_t['rmrf2'] = df_a_t['rmrf'] * df_a_t['rmrf']  # è‡ªå˜é‡rmrf^2
    df_a_t['cons'] = 1  # å¸¸æ•°é¡¹

                # ä½¿ç”¨T-Mæ¨¡å‹è®¡ç®—é€‰è‚¡æ”¶ç›Šã€æ‹©æ—¶èƒ½åŠ›
    regmodel = OLS(df_a_t.rprf, df_a_t[[
                    'cons', 'rmrf', 'rmrf2']], missing='drop', hasconst=True).fit()  # æ³¨æ„éœ€è¦æœ‰å¸¸æ•°é¡¹
    alpha = regmodel.params['cons']*250  # ç®€å•å¹´åŒ–é€‰è‚¡æ”¶ç›Š
    timing = regmodel.params['rmrf2']  # æ‹©æ—¶èƒ½åŠ›çš„å›å½’ç³»æ•°
    ptiming = (1 if regmodel.pvalues['rmrf2']
                        <= 0.1 else 0)  # æ‹©æ—¶èƒ½åŠ›æ˜¯å¦æ˜¾è‘— 0ä¸æ˜¾è‘— 1æ˜¾è‘—
    r2 = regmodel.rsquared_adj  # è°ƒæ•´åçš„R2

                # ä½¿ç”¨CAPMæ¨¡å‹è®¡ç®—è¶…é¢æ”¶ç›Š
    regmodel2 = OLS(
                    df_a_t.rprf, df_a_t[['cons', 'rmrf']], missing='drop', hasconst=True).fit()
    exaplpha = regmodel2.params['cons']*250  # CAPMè¶…é¢æ”¶ç›Š
    timing_y = exaplpha-alpha  # æ‹©æ—¶æ”¶ç›Š=CAPMçš„è¶…é¢æ”¶ç›Š-TMé€‰è‚¡æ”¶ç›Š

                # è¿æ°”è¿˜æ˜¯å®åŠ›é€šè¿‡BootStrapé‡å¤æŠ½æ ·è®¡ç®—alpha
                # é¦–å…ˆå–å‡ºCAPMæ¨¡å‹ä¸­çš„æ®‹å·®åºåˆ—ã€æ‹Ÿåˆå€¼
    dfres = pd.DataFrame({'fit': regmodel2.fittedvalues,
                                    'resid': regmodel2.resid})  # å–å‡ºCAPMæ¨¡å‹çš„å›å½’æ‹Ÿåˆå€¼å’Œæ®‹å·®é¡¹
    df_alpha_res = pd.merge(df_a_t, dfres, right_index=True,
                                        left_index=True, how='inner')  # æ•´åˆåŸå§‹æ•°æ®å’Œæ‹Ÿåˆæ•°æ®
    df_alpha_res = df_alpha_res.copy()
                # è®¡ç®—ä¼ªå‡€å€¼  y_hat=b1*(rm-rf)+resid,æ²¡æœ‰æˆªè·é¡¹
    df_alpha_res['fit_hat'] = regmodel2.params['rmrf'] * \
                    df_alpha_res['rmrf'] + df_alpha_res['resid']
    df_alpha_res = df_alpha_res.reset_index()  # æ–¹ä¾¿è·å–ç´¢å¼•
    num = len(df_alpha_res)  # æ ·æœ¬çš„ä¸ªæ•°

    sample_mean_list = []
    for i in range(1000):  # bootstrap 1000æ¬¡
        index = np.random.choice(range(num), num)  # æœ‰æ”¾å›æŠ½æ ·
        df_alpha_res_sample = df_alpha_res.iloc[index]
        reg_sample = OLS(df_alpha_res_sample.fit_hat, df_alpha_res_sample[['cons', 'rmrf']],
                                    missing='drop', hasconst=True).fit()
                    
        alpha_sample = reg_sample.params['cons'] * 250  # ä¼ªå‡€å€¼çš„å¹´åŒ–é€‰è‚¡æ”¶ç›Š
        sample_mean_list.append(alpha_sample)
                # plt.hist(sample_mean_list)                                             #æŸ¥çœ‹åˆ†å¸ƒ
    ser = pd.Series(sample_mean_list)
    p_alpha = len(ser[ser > exaplpha])/len(ser)  # ç®€å•è®¡ç®—æ‹’ç»åŸŸçš„æ¦‚ç‡
                # aplhaæ˜¯å¦æ˜¯è¿æ°”è¿˜æ˜¯å®åŠ› 0ä¸ºè¿æ°” 1ä¸ºå®åŠ›
    p_alpha = (1 if p_alpha <= 0.1 else 0)
    basic_factor_dict = {'ç»å¯¹æ”¶ç›Šç‡': abs_ret, 'å¹´åŒ–æ”¶ç›Šç‡': annual_ret,
                            'åŒºé—´æœ€å¤§å›æ’¤': interval_max_down, 'å¹´åŒ–æ³¢åŠ¨ç‡': annual_var,
                            'å¹´åŒ–å¤æ™®': annual_sharpe, 'å¡ç›æ¯”ç‡': interval_calmar,
                            'ä¸‹è¡Œæ³¢åŠ¨ç‡': down_var,'èƒœç‡':victory_days}
    al_ti = {'ç»å¯¹æ”¶ç›Šç‡':basic_factor_dict['ç»å¯¹æ”¶ç›Šç‡'], "å¹´åŒ–é€‰è‚¡æ”¶ç›Š": alpha, 'TMæ¨¡å‹è°ƒæ•´åR2': r2, "æ‹©æ—¶ç³»æ•°": timing,
                            "æ‹©æ—¶æ˜¾è‘—æ€§": ptiming, "å¹´åŒ–æ‹©æ—¶æ”¶ç›Š": timing_y, "alphaå®åŠ›": p_alpha}
    st.dataframe(al_ti)


